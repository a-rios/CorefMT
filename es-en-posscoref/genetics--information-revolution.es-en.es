La revolución de la información en la genética  
Averiguar los secretos del genoma humano sería imposible sin la manipulación computadorizada de cantidades ingentes de datos , incluida la mayoría de los tres mil millones de unidades químicas que componen el plan maestro genético de nuestra especie , pero lo que esa revolución de la " bioinformática " dummy-nonhum ha aportado , por encima de todo , es la confirmación absoluta de la base evolutiva de toda la vida en la Tierra .  
Los datos sobre secuencias , ya se refieran a proteínas o a ácidos nucleicos , se prestan muy bien al tratamiento informático , porque dummy-they son fáciles de digitalizar y descomponer en su-pl unidades constitutivas .  
Programas informáticos simples pueden comparar dos o más ristras de dichas unidades y evaluar los grados de similitud , buscar en enormes bases de datos para comparar las nuevas secuencias con las ya conocidas y juntar grupos de secuencias en forma de árbol genealógico .  
Las consecuencias de la investigación de las primeras proteínas estudiadas hace casi medio siglo fueron profundas .  
Todas aquellas secuencias eran bastante pequeñas - la insulina tiene unos cincuenta aminoácidos , según las especies - , pero la variación entre las especies resultaba clara .  
Mi interés comenzó con una de esas moléculas simples hace cuarenta años , cuando era un estudiante posdoctoral en Suecia .  
Los fibrinopéptidos son secuencias breves que resultan relativamente fáciles de purificar y tienen la virtud de cambiar en gran medida de especie a especie .  
Gracias a ello , dummy-we pudimos demostrar una clara correspondencia entre el registro de fósiles y la mayoría de los cambios observados en las secuencias de fibrinopéptidos .  
De modo que dummy-it resultó posible , evidentemente , interpretar el pasado evolutivo desde el punto de vista de las secuencias genéticas existentes .  
Pero fueron necesarios los progresos informáticos para seguir avanzando .  
En 1965 , Robert ledley inició la primera base auténtica de datos sobre secuencias , el Atlas de la estructura y la Secuencia de las proteínas .  
En 1967 , los investigadores prepararon un árbol genético de una veintena de animales y hongos que tenían prácticamente el mismo orden de ramificación que el que habría trazado un biólogo clásico , pese a que su-nonhum-sg computadora desconocía totalmente la anatomía , la paleontología y la embriología comparativas y otras características no moleculares de esos seres .  
Por último , en 1970 , una espléndida innovación informática dummy-nonhum permitió la alineación apropiada de secuencias de aminoácidos ( que es decisiva para todos los tratamientos de datos posteriores ) .  
Después se desarrolló la interpretación de los datos secuenciados a lo largo de dos dimensiones .  
Primero , hubo un interés natural por las relaciones entre organismos .  
Se formuló la hipótesis que a lo largo de todas las ramas de un árbol genético se producen cambios aleatorios , pero , según la proteína de que se trate , sólo dummy-nonhum sobrevive una pequeña fracción .  
Si esas tasas de supervivencia fueran constantes , se podrían calcular las distancias que separan las secuencias existentes .  
El segundo tipo de comparación se centró en proteínas parálogo , que descienden de un antepasado común dentro del mismo ser a consecuencia de duplicaciones de genes .  
Los dos tipos de comparación mostraron que las nuevas proteínas proceden de las antiguas , conforme a la predicción de la teoría evolucionista .  
En todos los organismos se producen constantemente duplicaciones de partes del genoma del Adn , principalmente a consecuencia de episodios aleatorios de desmembración y reunión .  
La mayoría de esos segmentos duplicados están condenados al olvido , porque cualesquiera proteínas que produzcan su-nonhum-sg genes son superfluas .  
Sin embargo , a veces el producto de un gen ligeramente modificado resulta beneficioso para la adaptación y nace una nueva proteína .  
Con frecuencia su-nonhum-sg función es muy similar a la antigua , pero a veces se produce un cambio radical .  
Después , en 1978 , se generalizó el uso de la secuenciación del Adn .  
Casi inmediatamente , una avalancha de nueva información genética llenó hasta rebosar la base de datos existente sobre la secuencia de las proteínas .  
Se creó un segundo depósito , Genbank , pero al principio se centró exclusivamente en las secuencias de Adn .  
Y , sin embargo , la información interesante estribaba en las secuencias de Adn traducidas , es decir , su-nonhum-sg equivalentes en proteínas .  
dummy-nonhum Fue uno de esos momentos poco frecuentes en que un aficionado tenía la oportunidad de competir con los profesionales .  
Conque dummy-I comencé mi propia base de datos , utilizando sobre todo secuencias de Adn traducidas ; dummy-I la llamé Newat ( Nuevo atlas ) .  
Provistos de una computadora muy primitiva y algunos programas muy simples preparados por un estudiante universitario , dummy-we comenzamos a comparar todas las secuencias nuevas con las secuencias anteriormente conocidas y descubrimos muchas relaciones totalmente inesperadas .  
Cuando se lanzó la Iniciativa del genoma humano al final del decenio de 1980 , la cantidad de datos ya no era el factor limitador para la obtención de nuevos conocimientos ; de repente dummy-it lo era su-masc-sg manejo .  
Muchos científicos se mostraron escépticos ante el proyecto del genoma humano .  
dummy-they Señalaban que el genoma humano contenía cien veces más secuencias de aminoácidos que las bases de datos existentes .  
Conque , ¿ cómo se identificarían los genes ?  
¿ Cómo se puede comparar algo que nunca se ha encontrado ?  
Pero cada uno de los genes de un genoma no es un concepto enteramente nuevo y no todas las secuencias de proteínas son posibles : de lo contrario , el número de secuencias diferentes sería muchísimo mayor que el de átomos en el Universo .  
Sólo una fracción minúscula de las secuencias posibles se ha producido alguna vez , mediante duplicación , multiplicación y modificación de un pequeño conjunto inicial de genes .  
A consecuencia de ello , la mayoría de los genes está emparentada con otros genes .  
Yo confiaba en que la bioinformática nos permitiera identificar todos los genes mediante la simple inspección de las secuencias , pero , después de que se completara la primera docena de genomas microbianos , la mitad , aproximadamente , de los genes siguen inidentificados , nivel que ha persistido en el caso de los cien primeros genomas completados , incluido el genoma humano .  
Incluso uno de los organismos más estudiados , la E. coli , tiene una abundancia de genes cuya función nunca se ha descubierto .  
Aun así , las ventajas del desciframiento de los genomas han sido inmensas .  
dummy-nonhum Puede que las promesas de rápidas aplicaciones médicas fueran exageradas , pero el valor inherente es inconmensurable : la capacidad para entender quiénes somos , de donde dummy-we venimos y qué genomas tenemos los seres humanos en común con el resto del mundo vivo .  
